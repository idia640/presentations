# How do we understand?
## 26 Mar 2019

---

## Outline

- Labs
- Brief note on language in the brain
- What is dialogue? (And why do we care?)
- Linguistic patterns are design patterns
- Considerations for UX design

Note:

These are the many things we will touch upon:

- Joint activities (macro interactions)
- Routines (micro-interactions)
- Dialog (& turn-taking)
- Social coordination
- Framing (positive, negative for example)
- Code-switching
- Footing
- Incremental understanding
- Signals and communicative acts
- Conventional meaning
- Detecting and correcting error
- Information packaging


Finally, the idea that linguistic patterns are design patterns

Language is an important topic for design, not just in terms of heuristics such as talk to your audience, avoid complexity, chunk information, etc. - but because language is foundational to interaction. And, of course, we use graphics and language in coordination to communicate to users. Interaction design is not just about the design of screen views, but is about designing to accommodate user goals and tasks.

---

## Emotion

- Smart brains are lazy
    - Most brain activity supports unconscious processes
    - Emotion drives thought

*Leverage habits and established behaviors*

Note:

Having read Kahneman chapter 1-9 and distinctions between System 1 and System 2, you may be thinking that System 1 is the emotional system and System 2 is distinctly rational. This is not quite right. System 1 is more a system that uses automated, intuitive, near effortless processes to decision-making, while System 2 requires controlled attention and conscious effort. Many of our neural pathways involve the limbic system and emotions have a particularly strong effect on memory.

---

## Emotional stimuli

<img src="images/emotions-in-advertising-surprise.png" width="70%" height="70%">

Note:

Capture attention with novel or surprising ideas to engage.

Top-down emotional stimuli combined with bottom-up  stimuli focus our attention.

Emotional messages leverage lower levels of conscious attention.

(Remember that positive or negative faces are noticed more easily than neutral faces.)

---

## Emotion in messaging

<img src="images/emotions-in-advertising-happiness.png" width="70%" height="70%">

Note:

After you've captured attention, sustain engagement through an individual's goals and motivations.

High-level arousal is more memorable. Negative emotions have an negative impact on cognitive performance and also associative memory.

---

## Emotion and retrieval

<img src="images/emotions-in-advertising-fear.png" width="70%" height="70%">

Note:

Creating emotional connections make it easier to retrieve information and make it more salient. Our implicit memory capacity is far larger than explicit. When we remember events, we also remember our feelings about that event.

What does this mean for creating a good first impression?

---

## "Behavior is our Medium"

<img src="images/mobility-in-healthcare.jpg" width="60%" height="60%">
https://s3.amazonaws.com/poptech_uploaded_files/uploaded_files/27/original/Project_Masiluleke_Brief.pdf

Note:

Robert Fabricant spoke about "behavior is our medium".

What did he mean by "medium"?

Part of what men meant is that behavioral change is not always limited to a decision in a moment in time but a series of processes around a decision.

Up until now, we have focused on snapshots in time -- perception, attention, memory & recall, emotion. I've emphasized the moment of decision, and not so much the goals, intentions, and process linked to that decision.

Fabricant brought into view for us, **the importance of a user's motivations, emotional state, and interaction during the course of a user's journey**. For example, he gave an example of the challenging problem of encouraging aids testing in South Africa. This involved a process:
- awareness
- help toward those actively seeking information
- support during testing
- and support following testing
- But the project also considered the importance of social bonds and channel for communication. To have sustained change you need to consider behavior from a macro-interactional perspective.

Thus, Fabricant focused on a number of examplars where design goals was intended for supporting and sustaining behavior change. And while not every design is concerned with changing behavior -- a persuasive design should be concerned with helping people achieve their goals -- and creating measurable **impact**.

---

## Objectives

- Understand how dialog relates to interaction design
  - Macro-interactions
  - Micro-interactions
  - Social processes
- Understand the importance of information packaging (chunking) for comprehension
- Understand the value of prevention / detection / repair in every step of user interaction
- Understand the importance of routinized interaction for consistency

---

## Prelude: Where is language?

<iframe width="560" height="315" src="https://www.youtube.com/embed/k61nJkx5aDQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

https://www.theguardian.com/science/2016/apr/27/brain-atlas-showing-how-words-are-organised-neuroscience

Note:

Across your entire cerebral cortex.

One person’s right cerebral hemisphere. The overlaid words, when heard in context, are predicted to evoke strong responses near the corresponding location. Green words are mostly visual and tactile, red words are mostly social. Illustration: Copyright Alexander Huth / The Regents of the University of California

---

## Dual process and language?

 **The** fast-thinking part **of your** brain creates **the** basic structure **of the** sentence (**the** words **here** marked **in** bold). **The** other words require **the** slower, more calculating part **of your** brain.

https://www.technologyreview.com/s/611640/data-mining-reveals-fundamental-pattern-of-human-thinking/

Note:

There is a difference between "function words" such as the articles, prepositions, pronouns, and other "closed class" words, and "content words".

"In English, the most popular word is the, which makes up about 7 percent of all words, followed by and, which occurs 3.5 percent of the time, and so on. Indeed, about 135 words account for half of all word appearances. So a few words appear often, while most hardly ever appear."

Other languages follow the same sort of distributional pattern.

A possible explanation for this distribution is accounted for by dual process theory, as described by Kahneman. There may be two ways in which we process words (or phrases) in the brain.

---

## Joint activity (macro interactions)

<iframe width="560" height="315" src="https://www.youtube.com/embed/3YxXsQMAvWg" frameborder="0" allowfullscreen></iframe>

<img src="images/discourse-continuum.png" align="center" width="50%" height="50%">

Note:


We're going to be talking about language, but let's focus in on goals and interaction since this has greater bearing on design than how we process language in the brain.

Here some examples of interaction that involve joint activity: teaching, job interview, game, dinner party, task.

For example, in a store transaction there are typically at least two roles: server and customer. What we communicate during interaction is partly defined by our role and our goals. But people also have their personal identities, beliefs, feelings & desires.

People participate in joint activities to achieve goals.

In most joint activities, people pursue multiple goals - public and private goals. Business goal (transaction), procedural goals (doing this quickly and efficiently), interpersonal goals (remaining polite), private agendas.

Joint activities require coordination. Conventional procedures and language use.

Joint activities are composed of joint actions.
- Greeting
- Request assistance
- Pay for items
- Conclude

Joint actions can be coordinated because they divide into phases: they have identifiable functions and entry/exits.

Phases get coordinated. (Imagine how your actions are coordinated when you are introduced to someone.)

For example, in conversation people take turns. These turns are distinguishable as intonation units. (Even if you can't hear what someone says, you can hear the rise and fall of their voice.) Entries and exits of turns are marked in syntax, morphology and intonation. For example, intonation units begin on a high pitch, drop gradually over the unit, and end with a distinctive fall or rise. They also tend to have a focal accented syllable at or near the end. These patterns are found in all languages. These intonational contours help aid listeners to project exit times more accurately.

Spoken language is highly synchronized. People are surprisingly good at judging entry and exit times, as well as accounting for processing difficulty.

There are boundaries - entries and exits that each participant has to recognize and understand.

People agree on the joint activity, who takes part, what roles they play before committing to the part.

Various dimensions:
- scriptedness (Marriage ceremony versus encounter in a hallway)
- formality (formal meeting, gossip)
- verbalness (phone call, tennis game)
- cooperativeness (restaurant to competitive game)
- governance "side-edness" (greeting a colleague, versus student in a class)

---

### Routinizing UX (micro interactions)

<img src="images/ui-patterns.gif" width="50%" height="50%">

http://ui-patterns.com

Note:

Some words seem to stick together. You seem to remember them together as if they are one object. This makes sense... it's chunking in action. For example,

- "I don't know"

You don't have to parse this to understand what it means. It's been routinized through repeated activation and use. Production and understanding require little cognitive effort.

But such phrases are also subject to priming. You know what to expect!

- "Cat in the ___"

If someone says: "cat in the __", you can fill in the blank. We chunk language into repeatable bits. These bits are linked frames. [Fillmore]

When we learn language, concepts and patterns become entrenched with frequent use.

Priming is also at play. UI components share familiar patterns so that you don't have to think to hard about what they mean.

Interaction design patterns and linguistic patterns share much in common. But while we all know how to use language, it takes specialized training to produce good interaction design patterns.

- Designers don't get continuous feedback of understanding by the user
- Production is not linked to comprehension in a real time feedback loop
- Patterns of behavior may not be aligned with the intended interaction.

Go to Google Images and search on "dialog box". What kind of variability do you see and is any of it confusing?

Easy to break design patterns:

- Information packaging
- Altering labels
- Altering positions of components
- Semantic mis-match between text and button labels
- Multiple choice tasks in a UI component

It's also easy to be complacent about design patterns.

---

## Is this dialogue interaction?

<img src="images/alexa.jpg" align="center" width="70%" height="70%">

Note:

What if one participant of this activity, is not human? Is it dialogue?

This is a human-initiated dialogue activity.

---

## How about this?


<img src="images/iphone.png" align="center" width="30%" height="30%">

Note:

This is also a dialogue activity.

- (Would you) answer a few simple questions.
- If you click "Get Started", this seems to be an acceptance.

The two acts together have the feel of "question-answer".

---

## You design for dialogue interaction!

- You are using language
- The user interacts in turns
- The interaction is cooperative
- ... and more

Note:

Both are human-computer dialogues. Perhaps, you don't think of yourself as designing dialogues yet, but you are!

---

## Can Alexa answer this?

- Q. Who was the first president of the United States?
- A. George Washington.
- Q. When was **he** born?
- ?

https://www.wired.com/story/inside-amazon-alexa-prize/

Note:

A year ago, the answer was 'no'. Now?

---

## Dialogue is multi-turn

Why don't Siri and Alexa do this (well) yet?
- Contextual expressions: for example, he/she/it, this/that/these..., here/there, yesterday/today...
- Pragmatic interpretation: "what you mean" versus "what you say"
- Error detection and repair

Note:

- You need some sort of context modeling to interpret deictic (e.g., pointing) expressions and those which refer to previous dialogue context.

Only last year, Amazon released a simple dialogue development kit.
https://developer.amazon.com/docs/custom-skills/dialog-interface-reference.html

---

*Humans are inherently wired for conversation -- and conversation is a kind of joint action*

Note: Humans are really good at dialogue. The capacity is built into us. This contrasts from the use of formal or written language which must be explicitly learned.

Okay, so we're wired for conversation. What does this have to do with interaction design and why bother with the theory.

Your understanding of language is largely unconscious, or at least largely automatic. You are highly competent -- expert -- at all of the things that Clark wrote about. And when you talk, you don't need to think about how language works. *But when you are designing interactive media, your conscious understanding of communicative processes will help you communicate better.*

An example where this really matters, but is still mostly done poorly: wrong user/password dialogues. While there are a few simple design patterns to draw upon, it's still very common to see this poorly implemented. Another example comes from broken links on the web. We are not computers... a 404 page is virtually meaningless to most users. No doubt you can think of other common examples!

---

## Linguistic patterns are design patterns

<img src="images/conversation.jpg" align="center" width="70%" height="70%">

Note:

Let's turn to the idea of linguistic patterns and how these relate to design patterns.

What are design patterns?

- F2F conversation is the most natural means of interaction
- Until now, we've looked at decision-making as a discrete action, but interaction is continuous. And we've also only considered decision-making from the context of a single person. But conversational acts require interaction and, generally, with more than one person. (An exception to this is self-talk).
- Conversation gives insight into how we organize, or package, information for comprehension, and how we exchange thoughts; we do so for much more than just information exchange.
- Conversations move through time, but there are devices for using the physical and mental environment to make some objects more salient.
- Conversation also gives insight into natural processes in error prevention, detection, and repair
- Finally, we will look at both macro-interactions and micro-interactions. Interaction viewed from both perspectives are important to design.

---

## Social coordination

<img src="images/mirror-neuron.png" align="center" width="70%" height="70%">


*Empathy is the basis for social connection and cooperation*

Note:

There is a link between empathy & cooperation.

Monkeys and people have neural systems in the pre-motor cortex to coordinate complex actions. When you perform an action certain neurons fire; the same neurons fire when you see someone perform an action. Neural connections to the parietal cortex, which integrates sensory information, are tuned when you do something or see someone do something.

Unsurprisingly, this pathway is also linked to your emotional system. If you see someone happy, you feel happiness. This is the basis of empathy. Empathy is the basis of social connection. How you are brought up matters? What you experience gets strengthened.

Early learning is important - half of neural connections die off by the age of 5.

People are inherently cooperative. And this is built into how we do everything, include communicate.

Points from another great talk from George Lakoff
https://www.youtube.com/watch?v=T46bSyh0xc0

---

## Participant framework (roles)

<img src="images/participant-framework.png" align="center" width="70%" height="70%">

[Goffman regions and audience segregation](https://youtu.be/OcFgCudciss?list=PLAZgQtqtqwF05EJW0CG3rMsE8jJrmA7BM)

*We design for an audience - audiences are imagined recipients*

Note:

Imagine from this diagram, that participants are in visual & aural range. They are also "bonified participants" (ratified) or not (e.g., by-standers).

"Side participants and overhearers help shape how speakers and addressees act toward each other. They also represent different ways of listening and understanding" (Clark)

Situations and activities are social. We use signals to convey shifts.

Evidence of structural significance of the social situation:

  - response cries (e.g., "ouch!")
  - collusion / byplay (between subset of participants)/ crossplay (participants and bystanders)
  - changed language in deference to bystanders

Moving beyond conversational interaction, there are
different sorts of talk (in different production formats): for example, political addresses, monologues (videoblog), panel discussions.

*Audiences are imagined recipients.*

---

## Framing information

<img src="images/sponsored-ads.png" align="center" width="70%" height="70%">

http://www.businessinsider.com/how-deceptive-sponsored-news-articles-could-be-undermining-trusted-news-brands-even-with-a-disclosure-message-2016-3

Example of [sponsored article](http://paidpost.nytimes.com/netflix/women-inmates-separate-but-not-equal.html?_r=0) on NYT

Note:

What is framing? When you take a picture, you frame the perspective that you'd like your audience to view. Similarly, information can be framed in much the same manner.

A study by Wojdynski and Evans found that 60% did not notice the sponsor disclosure label placed at the top of a sponsored ad.

"It also showed that readers are seven times more likely to recognize the labels that use some form of the words "advertising" or “sponsored,” than those which use more vague phrases like “brand voice” or “presented by.” Overall, only 20% of people in the study were aware that they were reading advertising, rather than objective, editorial content."

Why didn't they notice?

We are very skilled at perceiving and adjusting to footing changes in dialogue. So skilled, we may not consciously recognize transitions.

When Sociologist Irving Goffman talks about "footing", he means something along the lines of change in conversation stance; basically, he means framing.

Joint activities have structure -- but they too fall within and between frames -- another sort of structural unit.

---

## Code-switching
### What's up with that white voice?

<iframe width="560" height="315" src="https://www.youtube.com/embed/PY9RQFX28j0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

https://www.washingtonpost.com/lifestyle/style/whats-up-with-that-white-voice-the-tricky-art-of-linguistic-code-switching/2018/07/06/f083e34e-8044-11e8-bb6b-c1cb691f1402_story.html?utm_term=.5557d5e0e098

Note:

Code switching (for example, shifting between formal and informal registers) is a persistent feature of talk - though, we are most likely to change footing during certain (predictable) points during interaction: at structural junctures.

"Unconsciously or not, people code-switch to present what they believe (or are told) is a more favorable version of themselves — an instinct often heightened when interactions are conducted over the phone."

---

<img src="images/footing.jpg" align="center" width="70%" height="70%">


Note:

Footing is essentially -- stance. Journalists very frequently change stance during interviews. From one moment to the next, they may be moving between speaking as themselves or quoting someone else.

In this slide presentation from IA Summit 2010, the author notes a problem when a user attempts to this in Twitter. There are some mechanism to support footing changes in Twitter (for example RT), but there is confusion in this interaction because it wasn't clear that Nedaagain was simply translating others.

Changes of footing include the following:

- small talk to initiate and terminate a transaction
- enter into the business part of a conversation
- changes signaled by who is addressed, posture, dialect, etc.
- From Gumperz 1976
  1. direct or reported speech
  2. selection of recipient
  3. interjections
  4. repetitions
  5. personal directness or involvement
  6. new and old information
  7. emphasis
  8. separation of topic and subject
  9. discourse type, e g , lecture and discussion

Change in footing is a change in alignment - a change in our frame or stance - and this is reflected in how we both produce and comprehend language.

We can enact/mock someone else (as an actor). And, in fact, plays are embedded social scenes where this happens.

Imagine you are on the phone with a friend. Your friend yells, "Stop it!"

Language is understood with the context of frames. Not just the meaning, but from perspectives.

---

## Can you spot footing changes?

<iframe width="560" height="315" src="https://www.youtube.com/embed/gO-xmi1JgnE?start=0&end=60" frameborder="0" allowfullscreen></iframe>

Watch the first minute? What did you see?

Note:

"what's up man -- I kee -

how can I help you today"?
(overlapping) "hey"

"uh.. see what you guys have here"

*visual search*
(self) "smoothies"

*move back to counter*
alright... I'm going to go with a water and three cookies
alright.
so its gonna be a dollar, and a dollar 25, a dollar 50, and a dollar 75 (note gesture timing; and note that its obvious who is to pay)
alright.
here's this.
alright sweet.

break -- so what you do in a situation like this.

For example, someone telling a story in layer one may break out of the story to take a break or clear her voice. Layer two represents a meta-level above the story. And there can be more layers.

---

## Understanding is incremental

<img src="images/synchrony2.png" width="50%" height="50%">

Note:

Most actions aren't sequential but over-lapping in time. They may not be so discrete but continuous, as well. Timing is important to understanding meaning -- not just the sequence.

Clerk: I'll be right there.
You: Okay.

Immediate response versus delayed response? (Remember the importance of the long delay from Elizabeth Stokoe's talk. Seconds were forever!) A delayed response might indicate reluctance or disagreement.

---

## Synchrony and sequences

- Question | Answer
- Greeting | Greeting
- Invitation | (non) Acceptance
- Offer | (non) Acceptance
- Complaint | Apology / Denial
- Summons | Response
- Assertion | Assent
- Request | Acceptance
- Promise | Acknowledgement
- Thanks | Acknowledgement
- Goodbye | Goodbye

Note:

Exchanges generally accomplished in phases: presentation and acceptance.

These sequences are called adjacency pairs - two ordered utterances by different speakers. The form of the second depends on the form of the first.

Some times there is a pre-sequence - set up for a joint action. For example, taking a step forward before offering a hand.

We also have mechanism for signaling shifts. A
"discourse marker" can signal change in topics, change of footing, difference of opinion, digression, etc.

"Oh, there's something I wanted to ask you"
"So..." (discourse marker)

Because conversational speech is so highly coordinated and works incrementally, we have a sophisticated ability to detect errors and repair them. One thing we do unconsciously is look for positive evidence of understanding.

1. Assertions of understanding (could include backchannel response - uh-huh, m, I'see, nod)
2. Presupposition of understanding - speaker A continues speaking.
3. Displays of understanding - B displays understanding
4. Exemplification of understanding - paraphrase, iconic gesture, etc.

There is synchrony between speakers and also among speakers and listeners. Onset of gestures timed with prosodic rhythm of speech. Rhythm is crucial for conversation understanding and outcome. Comparable to musical performance.

Pitch is a carrier of non-verbal information (as body language) and speakers tend to synchronize with their conversational partners.

If you are interested in how people coordinate language using speech and gesture, researchers such as Birdwhistle, Kendon and others have studied synchrony and rhythm in conversation. In HCI, these are important areas of study for the development of conversational avatars.

---

## Signals and communicative acts

*"The joint act of one person signaling another and the other recognizing what was meant is called a communicative act."*


<img src="images/gaze.png" align="left" width="30%" height="30%">

<img src="images/live-chat.png" align="right" width="50%" height="50%">

Note:

Gaze is a coordinating device that participates in turn-taking. We not only communicate using gestures (e.g., head nod for 'assent', we can coordinate communication via gestures.

([Foulsham & Kingstone, 2005](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0136905))
]

Word and phrases are linguistic signals. They acquire meaning through convention.

Signals mean something, but they are also coordinating devices. If a server in a restaurant says, "I'll be right there", its a signal to coordinate our actions.

Eye gaze and body posture can also be used for signaling. These can also be communicative acts.

People generally adhere to a cooperative principle: make your conversational contribution such as required, at the stage at which it occurs, by the accepted purpose or direction of the talk exchange in which you are engaged. This is a complicated way of saying that people generally say something relevant, informative, neither too much or too little, nor in some obscure/ambiguous way unless intended.

"Could you turn up the heat?"
"Yes" (but taken literally rather than as a request)

Linguistic signals also participate in footing changes.

Student training video from earlier:
"Hey man"
"Can I help you"

What are some other ways we might signal in a UI?

---

## Conventions and coordinating devices


<img src="images/tips.jpg" align="left" width="20%" height="20%">

<img src="images/cart.png" align="right" width="60%" height="60%">

Note:

In conversation, external representations are important. As we orient ourselves in space, objects exist in that same space. Items can be manipulated and exchanged.

Something else we must do when use dialogue is
keep track of our moves and our partner's moves. It's not enough to predict what they will do next. People use coordinating devices to coordinate moves. You could do so by agreement (let's meet at 9). That, in itself is a joint action.

Conventions can also be coordinating devices. Conventions are a group (or community's) solution to a coordination problem. "In North
America, leaving a tip at the table in a restaurant is a solution to the recurrent problem of how to help pay the waiter or waitress." (Clark, pg 70)

---

## "Common ground" and belief updating

<img src="images/common-ground.png" align="left" width="20%" height="20%">

<img src="images/Shipping-Time.png" align="right" width="70%" height="70%">


Note:

Intrinsically, when you converse with someone, you are updating some notion of common ground. Common ground is cumulative. At each move in a dialogue, CG is updated. And not just shared knowledge. You may also be updating knowledge that is off the record.

Updating common ground:

- Public events so far (if joint activity)
  - What is said (linguistic and other signals)
  - What is talked about (time, place, referents, etc)
  - What is officially on the record (discourse record)
- Private or off record (including prior, shared knowledge/beliefs)

When participants cooperate, they share a mutual expectation or belief about what the other will do.

Common ground is a pre-requisite for coordination. Interlocutors have an awareness of what is salient to the other (or shared salience). If agree to go out to supper together and you are choosing a restaurant, you will consider what you know of your partner. What food they may like, location, etc. You make a choice on what you take to be your partner's and your own common ground.

We synchronize by adding information to commmon ground taking into account mutual salience; we keep track of what we know in common via the conversation as well as shared background knowledge.

This is reflected in the language we use - shared referents.

There are costs to grounding, as well.

- Medium (co-present?)
- Production
- Updating
- Repair

Principle of least collaborative effort: people try to minimize total effort spent on a contribution in both presentation and acceptance phases

Compare language used by air traffic controllers and a casual communication.

---

## Error prevention in dialogue

<iframe width="560" height="315" src="https://www.youtube.com/embed/rXXKn27rQLA?start=0&end=182" frameborder="0" allowfullscreen></iframe>

Note:

Up to 3:02

This is one way to prevent error in speech. If the dialogue is important, and the query / interaction is complex, this is a great solution.

Would this work for spoken systems like Alexa, Google Home, or Siri?

Spoken dialogue requires little training but is technical still very difficult.

It's brittle enough that error detection and repair are essential. Challenges include: speech recognition, variability in speaking style, disfluencies, accents, input channels such as cell phone, VOIP, background noisy environment and overlapping speech, etc.

Two approaches in conjunction:
- Prevention
- Detect error and repair

Discourse processes contribute to both: for example,

Task structure
Gaze
Chunking
Adjacency pairs
Backchanneling
Confirmation

How does Starbucks prevent error?
Starbucks uses a slot-filling technique

Every signal is part of presentation phase of a projected contribution. If there is trouble, a new project is initiated.

Repairs can also be initiated by the original contributor after seeing a mis-understanding in the partner's uptake.

"No, I meant..."

---

## Information packaging

  <iframe width="560" height="315" src="https://www.youtube.com/embed/ZBdQplMyWrs" frameborder="0" allowfullscreen></iframe>

Note:

How large a contribution should the two participants try to complete to minimize joint effort?

Limited by working memory. Depends on skill and purpose.

---

## Summary concepts

- Communication is social
- Think of your communications design from both a macro-interactional and micro-interaction perspective (task/joint action, communicative act)
- Be concerned with information packaging (chunking, salience) for comprehension
- Build in natural error prevention / detection / repair EVERYWHERE there is user interaction
- Support routinized interaction (consistency)

---

*We use the same social / cognitive mechanisms used in conversation for media interaction.*

Note:

"All forms of communication entail design, as the intent of communication is to be understood by others or by one’s self at another time. Communication design, then, is inherently social, because to be understood by another or by self at another time entails fashioning communications to fit the presumed mental states of others or of one’s self at another time." (B. Tversky, 2010, p. 6)

---

## Mirror Neurons

<iframe width="560" height="315" src="https://www.youtube.com/embed/t0pwKzTRG5E" frameborder="0" allowfullscreen></iframe>

---

## References

- Clark, H. H. (1996). Using Language. Cambridge University Press.

- Goffman, E. (1981). Forms of talk. University of Pennsylvania Press.

- Searle, J. R. (1969). Speech Acts. Cambridge University Press.

- Tversky, B. (2010). Visualizing thought. Topics in Cognitive Science, 3(3), 499–535.

Note:

<!--
Material that has been removed:

## Action ladders

<img src="images/action-ladder.png" align="center" width="70%" height="70%">

Note:

To succeed in joint projects (level 4), A & B need to ground what is taken to mean for B and to do that (level 3), they need to ground what A is presenting to B (level 2) and to do that they need to ground what behavior A is executing for B (level 1). Inference chain.

Principle of closure: Agents performing an action require evidence, sufficient for current purposes, that they have succeeded in performing it.

Imagine you press the button on an elevator and see no light. Do you wait and expect that it is coming? You are looking for evidence that your action had some sort of effect.

Principle of least effort: All things being equal, agents try to minimize their effort in doing what they intend to do.

---

## Speech Acts

<img src="images/speech-acts.png" align="center" width="70%" height="70%">

Note:

When you say something, you may mean more than what you say.

Utterances in conversation contain not only explicit meaning-based content but carry what is known as illocutionary force (John Searle). This force has something to do with intent; it performs a sort of action -- and sets up expectations in the minds of hearers.

For example,

a directive: Shut the window.
a question: Why here?
a declaration: The rain has started.
a promise: The job will be done by three o'clock.

Cues to the intentional force of an utterance might be the presence of specific words, but could also be communicated by tone, loudness, rhythm, etc.

This is something challenging to do in text chat -- hence the popularity of emoticons and the reason people react to the marked use of all caps, punctuation, and other uses of text to convey intent and feeling.

There are various ways a designer uses acts to acknowledge, inform, respond, query etc. They can be used to change the state of belief and, therefore, update common ground.

---

## Indexicality

<img src="images/banner-ad.png" align="center" width="70%" height="70%;">


Image credit: McGlaughlin, F. (2011, December). Banner Ad Design. In Marketingexperiments.com (pp. 1–40).

Note:

Indexicality or deixis - "I". Or even, "I'm speechless" pointing to oneself from outside of oneself.

Deixis refers to indexical behaviors - those that point to something or some state of affairs: attention, person, time, place or physical object, event, description, attitude, social identity, curses, expletives, etc.

"I don't give a damn" - referencing Gone with the Wind.

- Icons - signify through visual representation
- Index - sign linked to its object by a relation (button, back and forward arrows)
- Symbol - represents an object by convention

Back to our paid, sponsored content example:

"Many readers who notice the disclosure label are unaware that it is linked to the content of the article, thinking instead that they are looking at an unconventionally-placed banner ad, Wojdynski told Business Insider."

This level of ambiguity could have consequences on trust of producers.


---

## Multimodality

<img src="images/prediction-multimodal.jpg" align="center" width="50%" height="50%">

Image from: http://groups.csail.mit.edu/vision/vip/lmorency.html

Note:

If we process multiple streams of perceptual information in parallel, what is context?

- We know knowledge, emotion, etc. have an effect on visual perception. What about speech (or language)? Since there is some interaction between channels, there is improved efficiency when combining complementary information across channels. Interpretation is continuous and incremental.

- Does the converse hold? Does visual perception constrain real-time spoken language comprehension? (Yes! Via deixis, for example.)

-->
---
