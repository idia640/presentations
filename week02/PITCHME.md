# HCI Methodologies
### Experimentation
## 4 Feb 2020

---

## Primary methodologies

- Observational (e.g, ethnographic research)
- Survey
- Controlled experimentation

Note:

For the next two weeks we're going to talk about research methodologies. This week you need to learn something about 'experimentation' so that you can read your scientific paper.

Next week we will talk about ethnographic research and surveys. Ethnographic research is a methodology that will be useful for you to employ as we talk more about research you can do for your case study.

For your critical review, I'm assuming you know nothing about science nor how to read a scientific paper. You need to learn how to critical read a scientific paper because you will be the person on the UX team that has to deal with the question: "why are we doing it like that?"

Have you ever been frustrated from a client or developer who brushes off your idea because, "everyone has opinions" and they consider your advice simply an opinion? The point of this course is to give you tools to both create a persuasive design, but also defend it using cognitive principles, and where necessary, science. You may also need to refute "bad science", so we will focus much attention on this.

Did you ever imagine you would be the science person on the team? Since you will likely be the person is an expert on how humans interact with technology, you now have a new vocation as human-computer interaction researcher!

We will look at each of the methodologies above, but focus on hypothesis testing this week.

---

## Today's outline

- **Motivation**
- Objectives
- Controlled Experimentation

---

# Why do we need to know this stuff?

Note:

This point of this segment is to help you understand the importance of questioning assumptions and to think like a scientist. Part of how you will be persuasive in your own design pitches is using science as evidence where you can.

---

## Scientists are people
- They are inquisitive, but subject to the same biases as the rest of us.
- They work within a *paradigm*.
- Scientific observations are framed within a given paradigm.

Note:

Paradigm - A model of reality. Concepts, theories, methodologies, conventions.

Thomas Kuhn (Structure of Scientific Revolutions) - "Normal science is about accumulating knowledge".

Sometimes technological (or societal) advances make it possible to observe or measure phenomena that were not measurable before. In such cases, there may be anomalous observations that cause a shift to a new paradigm.

Example (Okay, I admit I was just reading this book...):

If you find this interesting, the story is described in great detail in [The Gene: An Intimate History](https://www.amazon.com/Gene-Intimate-History-Siddhartha-Mukherjee/dp/1476733503) by Siddhartha Mukherjee. This is a fascinating story with many players, but focuses on how it is we know about something that was invisible for many years and how it changed humanity's understanding of itself.

Why is it we share traits with our parents? Aristotle thought that it was the fluids transmitted by our parents which gave form to our physical beings. In the late 1700's, Erasmus Darwin suggested that animals arise from a "living filament" that has the power to acquire new parts in response to stimuli, and that each successive generation could improve over the last. A French scientist, Lamarck argued that characteristics during a lifetime could be passed to offspring. Because there was insufficient observational data to fully back these ideas, theories of evolution abounded.

But in the 18th century, scientists studying plant and animal diversity began to experiment with hybridization. One such person was the monk Gregor Mendel, a detail-oriented man who who took copious notes on hybridization of pea plants, was interested in statistical properties of traits through successive hybridization of plants. He discovered traits were calculable from statistical rules. There was gathering evidence from Charles Darwin and others to suggest something within organisms could pass on to successive generations.

It was not blood (as Aristotle hypothesized), since Francis Galton performed blood transfusions, ultimately, disproving transmission through blood. Weismann performed an experiment of removing tails from white mice and found that no mice were born without tails, giving strong evidence against Lamark's theory.

Ultimately, in 1910, Morgan, looking at inheritance in fruit flies, discovered sex-links recessive traits and he traced these to sex chromosomes (visible via a light microscope). Stemming from this work, we discovered genes on chromosomes and the mechanism by which inheritance occurs. This change was **precipitated by changes in technology which allowed us to make new observations - but also by changes in thinking in scientific discourse**.

Mukherjee says that we're living in a post-genomic world -- we can now read and write ourselves. This is a new *paradigm shift*.

---

## Science is social (and political)

- Pressure from "authorities" and peers (within a paradigm)
- Need for grants, publications, etc.
- Media hype

Note:

Science is subjective and political. Paradigms are backed by those with prominent reputations or within the majority. We will look at this sort of influence later in the semester.

---

# So what?

Note:

Science is full of bias. To top it off, the media seems to assume that anything published a scientist is valid.

---

## Question what seems authoritative -- scientific papers

-  "Normal" science
  - Publishing favors "new" and interesting work - claims may be over-stated
  - <a target="_blank" href="http://arstechnica.com/science/2016/03/social-science-reproducibility-not-great-but-not-as-bad-as-reported/">Results may not be reproducible</a>
  - <a target="_blank" href="http://www.psychologicalscience.org/index.php/convention/the-curse-of-knowledge-pinker-describes-a-key-cause-of-bad-writing.html">Writing may be "opaque"</a>

Note:

The first link is to an article about the "Reproducibility Project" which aims to replicate 100 empirical studies from several prominent journals in Psychology.

What is reproducibility? It's the ability for someone else -- not the author -- to replicate the same study and with the same results. This is important in social science, since people tend to believe the results of a single study generalize across people, time, and culture. But, of course, and despite this, a social context is variable and difficult to reproduce.

The Reproducibility Project sprung out of a "crisis" from a [year of horrors](http://ejwagenmakers.com/2012/Wagenmakers2012Horrors.pdf) in 2011 where it was found that the psychologist Diederik Stapel published at least 30 papers on fabricated data and where John Bargh's study where participants walk more slowly after being primed with the "old" stereotype failed replication. On top of this, the [Open Science Collaboration](https://osf.io/vmrgu/) found that only 36% of 100 studies in psychology, could be replicated.

One of the things you'll learn from this segment of the course is that scientists write in a narrowly proscribed manner. While the structure of scientific papers makes it easy to parse and read them once you know what to expect, the language used can be obscure an confusing -- and there is little incentive to make such writing easier to understand.

Reading from the Pinker article above: (as it pertains very well to design, in general):

Pinker: “I think the curse of knowledge is the chief contributor to opaque writing,” Pinker explained. “It simply doesn’t occur to the writer that readers haven’t learned their jargon, don’t seem to know the intermediate steps that seem to them to be too obvious to mention, and can’t visualize a scene currently in the writer’s mind’s eye. And so the writer doesn’t bother to explain the jargon, or spell out the logic, or supply the concrete details — even when writing for professional peers.”

> The slow and integrative nature of conscious perception is confirmed behaviorally by observations such as the “rabbit illusion” and its variants, where the way in which a stimulus is ultimately perceived is influenced by poststimulus events arising several hundreds of milliseconds after the original stimulus.

Pinker said that despite teaching and doing research in perception for almost 40 years, he “had no idea” what the sentence meant, could not identify what the writer was referring to by “a stimulus,” and had to look up the definition of rabbit illusion, which he discovered to be an obscure phenomenon in cutaneous perception:

“[I]t works as follows: The subject closes his eyes and sticks out his arm. The experimenter taps him three times on the wrist, three times on the elbow, three times on the shoulder, and it feels like a continuing series of taps running up the length of your arm, kind of like a hopping rabbit — hence, ‘the rabbit illusion.’

“Well, why didn’t they just say that?” Pinker asked, drawing chuckles from the audience.

But countering the curse of knowledge involves more than just empathizing with the reader, since social psychology studies show “that we’re not very good at figuring out what other people are thinking, even when we try really, really hard,” Pinker said.

Writers should, for example, show early drafts of their work to a representative reader. “You’d often be surprised to find that what’s obvious to you is not obvious to anyone else,” he said. They also can rewrite their piece several times without adding content, with the single goal of simply making the prose understandable, he added.

---

## "Sketchy" science

<img align="right" width="20%" height="20%" src="images/gap.jpg">

  - "Dodgy claims"
  - Journalistic error
  - <a target="_blank" href="http://www.chronicle.com/blogs/linguafranca/2012/03/15/bad-science-reporting-effect/">"Bad science" reporting effect</a>
  - "Gladwellian gap"

*We need to understand conventions scientists use to communicate their findings.*

Note:

"Dodgy claims" - see Ben Goldacre video below.

---

## "Dodgy claims"
<br>
<iframe src="https://embed-ssl.ted.com/talks/ben_goldacre_battling_bad_science.html" width="640" height="360" frameborder="0" scrolling="no" webkitAllowFullScreen mozallowfullscreen allowFullScreen></iframe>

Note:

Watch the first few minutes at least.

- We're impressed by authority
- Distortion of evidence - lab study in a petri dish extrapolated to you
- Compare effects against nothing (just "better than nothing" -  think about placebo effects)
- Personal stories (e.g., cure of Alzheimer's)
- "missing data" - negative trails are missing. Companies routinely withhold this sort of data. Tamiflu - promise that this drug reduces the complications of flu (pneumonia & death). But scientists are unable to get this data.

---

## Journalistic Error

<a target="_blank" href="https://www.bostonglobe.com/news/politics/2015/10/20/donald-trump-and-ben-carson-speak-grade-school-level-that-today-voters-can-quickly-grasp/LUCBY6uwQAxiLvvXbVTSUN/story.html">Boston Globe: Oct 20, 2015</a>

"The Globe reviewed the language used by 19 presidential candidates, Democrats and Republicans, in speeches announcing their campaigns for the 2016 presidential election. The review, using a common algorithm called the **Flesch-Kincaid readability test** that crunches word choice and sentence structure and spits out grade-level rankings, produced some striking results."

Note:

"The Republican candidates — like Trump — who are speaking at a level easily understood by people at the lower end of the education spectrum are outperforming their highfalutin opponents in the polls. Simpler language resonates with a broader swath of voters in an era of 140-character Twitter tweets and 10-second television sound bites, say specialists on political speech."

Does Flesch-Kincaid apply?? NO. It was designed for written text and not speech. (It has other flaws, as well. See punctution example on next page.)

---

## "Flesch Kincaid"

<img align="right" width="90%" height="90%" src="images/flesch-kincaid.png">

Credit: <a target="_blank" href="http://languagelog.ldc.upenn.edu/nll/?p=21847">LanguageLog Blog</a>

Note:

Do you see a difference in language use here?

---

## "Gladwellian gap"

<img align="right" width="20%" height="20%" src="images/DavidAndGoliath.jpg">
"Gladwell **proves** that not only do many successful people have dyslexia, but that they have become successful in large part because of having to deal with their difficulty."

Observation from a source quoted in <a target="_blank" href="http://www.slate.com/articles/health_and_science/science/2013/10/malcolm_gladwell_critique_david_and_goliath_misrepresents_the_science.html">Chabris, Slate Magazine, Oct 2013</a>

Note:

I'm a Gladwell fan, but it's important to understand the context of his writing. He's a persuasive story-teller.

- Malcolm Gladwell is hugely **influential** - perhaps, more so, than the scientists he reports on.
- He alternates between reports on scientific claims and rhetorical language: "If you take away the gift of reading, you create the gift of listening."

 From Gladwell:

“I am a story-teller, and I look to academic research … for ways of augmenting story-telling. The reason I don’t do things their way is because their way has a cost: it makes their writing inaccessible. If you are someone who has as their goal ... to reach a lay audience ... you can't do it their way.”

http://www.telegraph.co.uk/culture/books/authorinterviews/10335491/Malcolm-Gladwell-interview.html

"In his Telegraph interview, Gladwell again played down the seriousness of his work: "The mistake is to think these books are ends in themselves. My books are gateway drugs—they lead you to the hard stuff."

From the Slate article:

"And David and Goliath does cite scholarly works, books and journal articles, and journalism, in its footnotes and endnotes. But I wonder how many readers will follow those links, as compared to the number who will take its categorical claims at face value. And of those that do follow the links, how many will realize that many of the most important links are missing?"

Crude influence ratio cited by Googling the phrase:
- Gladwell: "proved" 5,300, "showed" 19,200 = 24,500 total
- Pinker: "proved" 9, "showed" 625 = 634 total

Tip: it is good practice to check footnotes and follow links to sources.

Also, check https://scholar.google.com to see citation counts.

---

## Objectives

1. Learn to be open-minded, but skeptical. Question what you read.
2.  Recognize where to find -- and how to interpret -- key information in a scientific article.
3. Recognize key differences between experimental and non-experimental research designs.
4. Recognize where potential problems may occur.

Note:

Elements of a scientific paper you will learn to identify.
- Central research question
- Hypothesis
- Research design
- Conditions and variables
- Results/Key findings

---

## UX Research Methods

<img align="center" width="60%" height="60%" src="images/user-research-methods.png">

Image credit: <a href="https://www.nngroup.com/articles/which-ux-research-methods/">Norman Nielsen</a>

Note:

Does not account for experimental studies. https://www.nngroup.com/articles/which-ux-research-methods/

- Both qualitative and quantitative may be interested in using both objective and subjective data. But, generally, quantitative studies focus on structured data while qualitative studies focus on more open-ended questions.

---
## Some dichotomies in HCI research methods

- Lab vs field (natural context)
- Participant report vs. researcher observation
- Quantitative vs qualitative
- Behavioral vs. attitudinal (do versus say)

Today the focus is on **Randomized experimental** (lab, observations, quantitative, behavioral)

Note:

There are a number of different ways to slice and dice research methods - but it's difficult to find a single representation that adequately describes such a multi-dimensional topic.

---

## Structure of research

<img width="50%" height="50%" src="images/research-study.png">

Note:

Image credit: Gliner, Morgan, and Leech (2011), p. 20

- Mature conventions
- **Papers follow the same well-defined structure**

---

## What if the question is very broad?

<img width="50%" height="50%" src="images/broad-research.png">

Note:

Image credit: Chow, S. (2010). p. 450

If you are interested in doing a quantitative master's or doctoral thesis using experimentation, this is how you would break down your problem.

Let's take a look:

Suppose you are interested in the question of whether people in small towns are friendlier than those from big cities.

If you want to understand the cause, you develop a substantive hypothesis to study. For example, "environmental pleasantness eliminates irritability."

"A substantive hypothesis is a conjecture about the relation between two or more variables. It is called “substantive” because it has not yet been ∗operationalized and in order to distinguish it from the kind of statistical hypothesis used in ∗hypothesis testing." Chow, S. (2010)

A substantive hypothesis may be difficult to study without breaking down the problem into smaller questions or studies. You may need to eliminate other possible causes or ask the same question in different ways.

Ultimately, for any individual study, you need observable, quantifiable measures that can be examined statistically, and you need to be able to identify those variables that you can manipulate to study the effect on your dependent variable. In this case, the variable of interest is **irritability**.


---
## HCI research methods (deeper look)

<img align="center" width="90%" height="90%" src="images/hci-research-methods.png">

Inserted image from Gliner, Morgan & Leech (2011) p. 11

Note:

This slide puts into context all of the research methods we will be concerned with in this course. Let's walk through it.

We'll look at ethnographic research and survey methodology next week, but for this week you need to know the difference between experimental and non-experimental research designs.

---

## Randomized experimental

<img align="center" width="80%" height="80%" src="images/experimental.png">

Note:

In this example independent variables are active - they can be manipulated. However, it's not always the case that independent variables are active like this. We'll see this in quasi-experiments next.

A sample should be representative of the population you are studying. It needs to sufficiently sized and representative.

In this example, imagine that the treatment was the effect of a marketing campaign. One group was subject to a treatment, and the other was not.

Here we are only looking at one variable and that variable is categorical with just one distinction.

You could also imagine variables with multiple levels such as small, medium, and large.

And you could imagine being interested in something like assessing readability on the basis of multiple variables such as, text color, size, and font.

---

## Quasi-Experimental

The key difference between randomized experiments and quasi experiments is that in the latter, no random groups are assigned.

- For example,
 - Two university classes are given two different exam types. There is no way to randomize the selection of students since they are already assigned to the classes.
 - Groups where subjects had selected the treatment (e.g., stress reduction via Tai Chi versus meditation). Again, there is no way to randomize who gets which treatment.

---

## What is a Null Hypothesis?

<img align="center" width="90%" height="90%" src="images/null-hypothesis.png">

Note:

You can't prove something is true. Science rests on a principle that Karl Popper described as "falsifiability" - which basically means there is the means to dispute some claim about a theory.

The tool science uses to do this is inferential statistics. By studying a sample population, which is an analog of THE population, evidence inferred from the sample gives you confidence that the same experiment performed over the total population would derive the same results.

The way null hypothesis testing works is that you look for whether there is a difference between two groups; is there a relationship between independent variable(s) and a dependent variable -- given all else is the same. If you find a statistical difference -- the behavior of the treatment group is sufficiently different from the control group -- then you have evidence to support an alternative hypothesis to the null hypothesis.

Ideally, the alternative hypothesis has either explanatory or predictive power. We use randomized controlled experiments for the purpose of giving evidence for a causal relation between variables.

---
## Conditions & variables

- Conditions - What are the groups? In the previous example, treatment versus control.

- Variables. What kind of variables are there?
  - **Independent variable (IV)** - Presumed cause. The variable you are studying.
    - Active - e.g., positive/normal SUS. The variable is manipulated.
    - Attribute - Property of a person such as age.
  - **Dependent variable (DV)** - the outcome variable that depends on the IV.
  - **Extraneous** - Variables that need to be ruled out.
  - **Confounding** - interacts with both the IV and DV.

Note:

Extraneous: For example, minor visual differences in cross-browser display.

When there are more than two IVs, the design is said to be factorial.

---
## Confounding variable

<img align="center" width="90%" height="90%" src="images/confounding.png">


Note:

A good example for a confounding variable is provided by the example of whether or not activity level (hi/low) has a causal effect on weight gain. Age is a confounding variable since it also has an effect on weight gain. You would need to control for age.


---

## Non-Experimental (Observational)

<img align="center" width="60%" height="60%" src="images/non-experimental.png">

Note:

Suppose you want to understand voter behavior. You could use quantitative methods to do so.

- You could summarize data by population attributes.
- You could relate variables such as age, income, gender, and education level to make some sort of prediction
- you could also compare different sub-populations  to look at differences between them.

Note these are all inherent attributes of a person - you can't assign them these attributes.

---

## Back to the overview

<img width="90%" height="90%" src="images/research-overview.png">


Note:

 Image credit: Gliner, Morgan, and Leech (2011), p. 11

---

# Next week

- Critical Review due
- Labs: How to present a scientific paper;  ethnographic research
- More on research methods: Ethnography

---
## References

Chow, S. "Experimental Design." In Encyclopedia of Research Design. Neil J. Salkind, editor. (Thousand Oaks, CA: Sage, 2010), pp. 448-453.

Gliner, J., Morgan, G., & Leech, N. (2011). Research methods in applied settings: An integrated approach to design and analysis. Routledge.

Kuhn, T. (2012). The structure of scientific revolutions. University of Chicago press.

---
## References (cont.)

Sauro, J., & Lewis, J. (2011, May). When designing usability questionnaires, does it hurt to be positive? In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (pp. 2215-2224). ACM.

---
